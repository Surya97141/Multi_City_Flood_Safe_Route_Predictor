{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc163ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86329f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'District'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_17604\\2268752034.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m impact = pd.read_csv(\u001b[33m'../data/raw/flood/District_FloodImpact.csv'\u001b[39m)\n\u001b[32m      5\u001b[39m dfsi = pd.read_csv(\u001b[33m'../data/raw/flood/DFSI.csv'\u001b[39m)\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m master = area.merge(impact, on=\u001b[33m'Dist_Name'\u001b[39m, how=\u001b[33m'outer'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m master = master.merge(dfsi, on=\u001b[33m'District'\u001b[39m, how=\u001b[33m'left'\u001b[39m)\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m master.to_csv(\u001b[33m'../data/processed/flood_master.csv'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     11\u001b[39m \n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10855\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m     ) -> DataFrame:\n\u001b[32m  10857\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10858\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m         return merge(\n\u001b[32m  10860\u001b[39m             self,\n\u001b[32m  10861\u001b[39m             right,\n\u001b[32m  10862\u001b[39m             how=how,\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'District'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "area = pd.read_csv('../data/raw/flood/District_FloodedArea.csv')\n",
    "impact = pd.read_csv('../data/raw/flood/District_FloodImpact.csv')\n",
    "dfsi = pd.read_csv('../data/raw/flood/DFSI.csv')\n",
    "\n",
    "master = area.merge(impact, on='Dist_Name', how='outer')\n",
    "master = master.merge(dfsi, on='District', how='left')\n",
    "\n",
    "master.to_csv('../data/processed/flood_master.csv', index=False)\n",
    "\n",
    "print(\"Flood EDA Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ab0cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFSI columns: ['Unnamed: 0', 'State_Name', 'DFSI']\n",
      "Area columns: ['Dist_Name', 'Percent_Flooded_Area', 'Parmanent_Water', 'Corrected_Percent_Flooded_Area']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "area = pd.read_csv('../data/raw/flood/District_FloodedArea.csv')\n",
    "impact = pd.read_csv('../data/raw/flood/District_FloodImpact.csv')\n",
    "dfsi = pd.read_csv('../data/raw/flood/DFSI.csv')\n",
    "\n",
    "# Check columns\n",
    "print(\"DFSI columns:\", dfsi.columns.tolist())\n",
    "print(\"Area columns:\", area.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac60dbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Merged flood (area + impact) data saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "area = pd.read_csv('../data/raw/flood/District_FloodedArea.csv')\n",
    "impact = pd.read_csv('../data/raw/flood/District_FloodImpact.csv')\n",
    "\n",
    "master = area.merge(impact, on='Dist_Name', how='outer')\n",
    "master.to_csv('../data/processed/flood_master.csv', index=False)\n",
    "\n",
    "print(\"Done! Merged flood (area + impact) data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e286d9aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'State_Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'State_Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Before merging, create the correct column names\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m master[\u001b[33m'\u001b[39m\u001b[33mState\u001b[39m\u001b[33m'\u001b[39m] = master[\u001b[33m'\u001b[39m\u001b[33mState\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mState\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m master.columns \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mimpact\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mState_Name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m dfsi[\u001b[33m'\u001b[39m\u001b[33mDistrict\u001b[39m\u001b[33m'\u001b[39m] = dfsi[\u001b[33m'\u001b[39m\u001b[33mDistrict\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mDistrict\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dfsi.columns \u001b[38;5;28;01melse\u001b[39;00m dfsi[\u001b[33m'\u001b[39m\u001b[33mUnnamed: 0\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Then do the merge\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'State_Name'"
     ]
    }
   ],
   "source": [
    "# Before merging, create the correct column names\n",
    "master['State'] = master['State'] if 'State' in master.columns else impact['State_Name']\n",
    "dfsi['District'] = dfsi['District'] if 'District' in dfsi.columns else dfsi['Unnamed: 0']\n",
    "\n",
    "# Then do the merge\n",
    "master = master.merge(dfsi, left_on=['Dist_Name', 'State'], right_on=['District', 'State_Name'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5eeee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'State_Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_17604\\3252105303.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'State_Name'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m impact.columns:\n\u001b[32m      6\u001b[39m     master[\u001b[33m'State_Name'\u001b[39m] = master[\u001b[33m'State_Name'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'State_Name'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m master.columns \u001b[38;5;28;01melse\u001b[39;00m impact[\u001b[33m'State_Name'\u001b[39m]\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Now merge DFSI using Dist_Name and State_Name from master, District and State_Name from dfsi\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m master = master.merge(dfsi, left_on=[\u001b[33m'Dist_Name'\u001b[39m, \u001b[33m'State_Name'\u001b[39m], right_on=[\u001b[33m'Unnamed: 0'\u001b[39m, \u001b[33m'State_Name'\u001b[39m], how=\u001b[33m'left'\u001b[39m)\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m master.to_csv(\u001b[33m'../data/processed/flood_master.csv'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m print(\u001b[33m\"Done! Merged with vulnerability.\"\u001b[39m)\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10855\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m     ) -> DataFrame:\n\u001b[32m  10857\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10858\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m         return merge(\n\u001b[32m  10860\u001b[39m             self,\n\u001b[32m  10861\u001b[39m             right,\n\u001b[32m  10862\u001b[39m             how=how,\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1307\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1308\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1309\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1310\u001b[39m                         lk = cast(Hashable, lk)\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m                         left_keys.append(left._get_label_or_level_values(lk))\n\u001b[32m   1312\u001b[39m                         join_names.append(lk)\n\u001b[32m   1313\u001b[39m                     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1314\u001b[39m                         \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "\u001b[32mc:\\SEM III\\GBM_sih\\gbm_sih_env\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'State_Name'"
     ]
    }
   ],
   "source": [
    "# Merge area and impact\n",
    "master = area.merge(impact, on='Dist_Name', how='outer')\n",
    "\n",
    "# Add the State_Name column from impact to the master frame\n",
    "if 'State_Name' in impact.columns:\n",
    "    master['State_Name'] = master['State_Name'] if 'State_Name' in master.columns else impact['State_Name']\n",
    "\n",
    "# Now merge DFSI using Dist_Name and State_Name from master, District and State_Name from dfsi\n",
    "master = master.merge(dfsi, left_on=['Dist_Name', 'State_Name'], right_on=['Unnamed: 0', 'State_Name'], how='left')\n",
    "\n",
    "master.to_csv('../data/processed/flood_master.csv', index=False)\n",
    "print(\"Done! Merged with vulnerability.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32958b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "(744, 8)\n",
      "    Dist_Name  Percent_Flooded_Area  Parmanent_Water  \\\n",
      "0    Adilabad              1.209759         0.221044   \n",
      "1  Agar Malwa              0.536889         0.338892   \n",
      "2        Agra              4.133356         0.101930   \n",
      "3   Ahmadabad              4.222293         0.122458   \n",
      "4  Ahmadnagar              0.691348         0.697617   \n",
      "\n",
      "   Corrected_Percent_Flooded_Area  Human_fatality  Human_injured  Population  \\\n",
      "0                        0.988715             174              0      802880   \n",
      "1                        0.197996               2              0      702666   \n",
      "2                        4.031427             133             32     5296620   \n",
      "3                        4.099835             177             23     8738876   \n",
      "4                        0.006269              50             18     5113145   \n",
      "\n",
      "   Mean_Flood_Duration  \n",
      "0                  8.0  \n",
      "1                  6.0  \n",
      "2                 20.0  \n",
      "3                 12.0  \n",
      "4                  4.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "area = pd.read_csv('../data/raw/flood/District_FloodedArea.csv')\n",
    "impact = pd.read_csv('../data/raw/flood/District_FloodImpact.csv')\n",
    "\n",
    "master = area.merge(impact, on='Dist_Name', how='outer')\n",
    "master.to_csv('../data/processed/flood_master.csv', index=False)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(master.shape)\n",
    "print(master.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbm_sih_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
